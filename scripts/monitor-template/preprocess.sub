#!/bin/bash
#SBATCH --nodes=1                # node count
#SBATCH --ntasks=1               # total number of tasks across all nodes
#SBATCH --cpus-per-task=1        # CPUS to use when using data parallelization
#SBATCH --time=05:00:00          # total run time limit (HH:MM:SS)

# A slurm script to run ALL of preprocessing

# load modules
module load singularity-3.5.3
module load r-4.0.2-gcc-8.2.0-tf4pnwr
module load miniconda3-4.5.11-gcc-8.2.0-oqs2mbg

# set variables & paths

# automatically get project name
project=$(dirname $(pwd))
output_path="${project}/derivatives/preprocessed"
data_source="$project/sourcedata/checked/redcap/"

# constant paths
sing_image="/home/data/NDClab/tools/instruments/containers/singularity/inst-container.simg"
json_scorer="/home/data/NDClab/tools/instruments/scripts/json_scorer.py"
survey_data="/home/data/NDClab/tools/instruments/scripts/surveys.json"

# get most recent redcap file for processing
elements=$(ls $project/sourcedata/checked/redcap/)
time_stamp='\d{4}-\d{2}-\d{2}_\d{4}'
stem="202201v0readAloudval_DATA_${time_stamp}.csv"

# return single instance if only one file
if [[ ${#elements[@]} == 1 ]]; then
    input_file=${elements[0]}
elif [[ ${#elements[@]} == 0 ]]; then
    echo -e "\\t ${RED}Error: Redcap data empty. Exiting.${NC}"
    exit 1
else
    # find newest file by comparing timestamp strings
    input_file="${elements[0]}" 
    newest_time=$(echo "$input_file" | grep -oP "$time_stamp")
    for i in "${!elements[@]}"; do
        file_name="${elements[$i]}"
        file_time=$(echo "$file_name" | grep -oP "$time_stamp")
        if [[ "$file_time" > "$newest_time" ]]; then
            newest_time=$file_time
            input_file=$file_name
        fi
    done
    echo "FOUND NEWEST FILE $input_file"
fi

# run instruments to preprocess survey data
singularity exec --bind $project,/home/data/NDClab/tools/instruments \
    $sing_image \
    python3 $json_scorer \
    $data_source/$input_file \
    $survey_data \
    $output_path

# update central tracker using instruments data
# todo: need to programtically get output file
python inst-tracker.py "${output_path}/202201v0readAloudval_SCRD_2022-06-04_1550.csv"

# run R scripts that require R modules
singularity exec --bind $project /home/data/NDClab/tools/containers/R-4.1.2/R-con.simg Rscript "${project}/code/preprocPavlovia.R" ; \
                                                                                       Rscript "${project}/code/preprocTimingAndPitch.R" ; \
										                                               Rscript "${project}/code/preprocDisfluencies.R"